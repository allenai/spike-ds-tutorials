{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6d53bd",
   "metadata": {},
   "source": [
    "# Get Sentences with SPIKE's query API\n",
    "\n",
    "The following script takes a spike query and lists of words, runs the query on SPIKE and downloads a list of sentences that match the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cde2902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81291a53",
   "metadata": {},
   "source": [
    "### Materials to prepare\n",
    "This script assumes the following materials:\n",
    "1. json file with the desired patterns, located at `./src`, in the following format:\n",
    "```\n",
    "{\n",
    "    \"0\": {\n",
    "        \"query\": \"$[w={roles}]guitarist <E>musician:[e=PERSON]John plays the piano\",\n",
    "        \"type\": \"syntactic\", # other options are boolean or token \n",
    "        \"case_strategy\": \"ignore\", # other options are exact or smart \n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"roles\"] # should match the name within brackets in the query. Leave empty list if irrelevant.\n",
    "    },\n",
    "    \"1\": {\n",
    "        ...\n",
    "    }...\n",
    "}\n",
    "```\n",
    "2. Lists of words stored in text files under `../data/lists`. The name of the file should match the name in the patterns file. Note you can download the list straight from spike, or create one yourself, with a single item per line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59f6f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKE_MATCHES_DIR = '../data/spike_matches'\n",
    "PATTERNS_FILE = 'patterns.json'\n",
    "LISTS_FILE = '../data/lists'\n",
    "LIMIT = 1000\n",
    "ENTITY_TYPE='PERSON' # the type of entity you are looking for. If your desired capture is not an entity, leave an empty string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "623cb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patterns_from_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def write_pattern_matches(pattern):\n",
    "    pattern_matches = search_single_query(pattern)\n",
    "    return pattern_matches\n",
    "\n",
    "        \n",
    "def search_single_query(pattern):\n",
    "    spike_url = \"https://spike.staging.apps.allenai.org\"\n",
    "    stream_location = get_stream_location(spike_url, pattern)\n",
    "    if not stream_location: return None\n",
    "    matches = list(search_stream(spike_url, stream_location, pattern))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def get_lists(pattern):\n",
    "    lists = defaultdict(list)\n",
    "    list_names = pattern[\"lists\"]\n",
    "    if list_names:\n",
    "        for name in list_names:\n",
    "            with open(f\"../data/lists/{name}.txt\", \"r\") as f:\n",
    "                for item in f.readlines():\n",
    "                    lists[name].append(item.strip())\n",
    "    return lists \n",
    "    \n",
    "\n",
    "def get_stream_location(spike_url, pattern):\n",
    "    dataset = \"wikipedia\"\n",
    "    url = spike_url + \"/api/3/multi-search/query\"\n",
    "    query_type = pattern[\"type\"]\n",
    "    query = pattern[\"query\"]\n",
    "    case_strategy = pattern[\"case_strategy\"]\n",
    "    lists = get_lists(pattern)\n",
    "    data= {\n",
    "        \"queries\": {\n",
    "            \"main\": {\n",
    "                query_type: query\n",
    "            }\n",
    "        },\n",
    "        \"data_set_name\": dataset,\n",
    "        \"context\": {\n",
    "            \"lists\": lists,\n",
    "            \"tables\": {\n",
    "            },\n",
    "            \"case_strategy\": case_strategy,\n",
    "            \"attempt_fuzzy\": False\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    if 'stream-location' not in response.headers:\n",
    "        return None\n",
    "    return response.headers['stream-location']\n",
    "\n",
    "\n",
    "def search_stream(spike_url, stream_location, pattern):\n",
    "    limit = LIMIT*5 if pattern[\"label\"] == \"negative\" else LIMIT\n",
    "    stream_url = spike_url + stream_location + f\"?include_sentence=true&limit={limit}&include_sentence=true\"\n",
    "    response = requests.get(stream_url)\n",
    "    results = [json.loads(jl) for jl in response.text.splitlines()]\n",
    "    if len(results) == 0:\n",
    "        print(f\"Couldn't find any results for pattern {pattern}\")\n",
    "    for result in results:\n",
    "        if result['kind'] in ['continuation_url', 'tip']: continue\n",
    "        data = result['value']['sub_matches']['main']\n",
    "        entities = [ent for ent in data['sentence']['entities'] if ent[\"label\"].startswith(ENTITY_TYPE)] if ENTITY_TYPE else []\n",
    "        yield {\n",
    "            'words': data['words'],\n",
    "            'captures': data['captures'],\n",
    "            'sentence_index': data['sentence_index'],\n",
    "            'highlights': data['highlights'],\n",
    "            'entities': entities\n",
    "            }\n",
    "\n",
    "        \n",
    "def main():\n",
    "    patterns = read_patterns_from_file(f'{PATTERNS_FILE}')\n",
    "    for idx, pattern in tqdm(patterns.items()):\n",
    "        label = pattern[\"label\"]\n",
    "        with open(f'{SPIKE_MATCHES_DIR}/{label}/{idx}.json', 'w') as f:\n",
    "            matches = write_pattern_matches(pattern)\n",
    "            if matches:\n",
    "                f.write(f\"{json.dumps(matches, indent=4)}\")\n",
    "            else:\n",
    "                print(\"no matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84ce0e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 6/6 [00:21<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088e65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
