{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d0b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c7a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "dataset = './musicians_dataset'\n",
    "outputs = './outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8eba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data_to_df(filepath, with_person=True):\n",
    "    tagged_data = []\n",
    "    sentence_number = 0\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            for tagged_word in line.split():\n",
    "                word, tag = tagged_word.split(\"-[\", 1)\n",
    "                if tag.startswith('B'):\n",
    "                    new_tag = \"B-MUS\"\n",
    "                elif tag.startswith('I'):\n",
    "                    new_tag = \"I-MUS\"\n",
    "                elif with_person:\n",
    "                    if tag.startswith('PB'):\n",
    "                        new_tag = \"B-PER\"\n",
    "                    elif tag.startswith('PI'):\n",
    "                        new_tag = \"I-PER\"                \n",
    "                    else:\n",
    "                        new_tag = \"O\"\n",
    "                else:\n",
    "                    new_tag = \"O\"\n",
    "                tagged_data.append([sentence_number, word, new_tag])\n",
    "            sentence_number += 1\n",
    "    return pd.DataFrame(tagged_data, columns=[\"sentence_id\", \"words\", \"labels\"])\n",
    "\n",
    "def get_dataset_parts(dataset_path):\n",
    "    devpath, trainpath, testpath = f\"{dataset}/dev.txt\", f\"{dataset}/train.txt\", f\"{dataset}/test.txt\"\n",
    "    test = ingest_data_to_df(testpath)\n",
    "    train = ingest_data_to_df(trainpath)\n",
    "    dev = ingest_data_to_df(devpath)\n",
    "    return dev, train, test\n",
    "\n",
    "def untag_dev_sentences(devpath):\n",
    "    output_path = f\"sentences_{devpath}\"\n",
    "    clean_sentences = []\n",
    "    with open(devpath, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            sentence = re.sub('\\-\\[[A-Z]*\\]',  '', line)\n",
    "            clean_sentences.append(sentence)\n",
    "    return clean_sentences\n",
    "\n",
    "\n",
    "def configure_model(labels=None, batch_size=16, model_type=\"roberta\", model_name=\"roberta-base\"):\n",
    "    model_args = NERArgs()\n",
    "    model_args.train_batch_size = batch_size\n",
    "    model_args.evaluate_during_training = True\n",
    "    model_args.labels_list = labels\n",
    "    model = NERModel(\n",
    "        model_type, \n",
    "        model_name, \n",
    "        args=model_args\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def send_prediction_to_conll(prediction, filepath):\n",
    "    with open(f\"{outputs}/dev_predictions.conll\", \"w\") as f:\n",
    "        for sent in predictions:\n",
    "            for token_dict in sent:\n",
    "                for k, v in token_dict:\n",
    "                    f.write(f\"{k} {v}\\n\")\n",
    "\n",
    "def document_results(experiment_name, outputs, results):\n",
    "    with open(f\"../experiments/{experiment_name}.json\", \"w\") as f:\n",
    "        details = dict()\n",
    "        # TODO: continue building results like in experiments/experiment1. \n",
    "        # paths: outputs/model_args.json ; outputs/best_model/config.json ; \n",
    "        # outputs/best_model/eval_results.txt (convert this to dict):\n",
    "        # eval_loss = 0.2069134594578492\n",
    "        # f1_score = 0.5806451612903225\n",
    "        # precision = 0.5765124555160143\n",
    "        # recall = 0.5848375451263538\n",
    "\n",
    "def main():\n",
    "    dev_set, train_set, test_set = get_dataset_parts(dataset)\n",
    "    clean_sentences = untag_dev_sentences(f\"{dataset}/dev.txt\")\n",
    "    musician_labels=[\"B-MUS\", \"B-PER\", \"I-MUS\", \"I-PER\", \"O\"]\n",
    "    model = configure_model(labels=musician_labels)\n",
    "    model.train_model(train, eval_data=dev_set)\n",
    "    predictions, raw_outputs = model.predict(clean_sentences)\n",
    "    \n",
    "    send_prediction_to_conll(prediction, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e01d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
