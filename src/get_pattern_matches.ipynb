{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6d53bd",
   "metadata": {},
   "source": [
    "# Get Sentences with SPIKE's query API\n",
    "\n",
    "The following script takes a spike query and lists of words, runs the query on SPIKE and downloads a list of sentences that match the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde2902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import jsonlines\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81291a53",
   "metadata": {},
   "source": [
    "### Materials to prepare\n",
    "This script assumes the following materials:\n",
    "1. json file with the desired patterns, located at `./src`, in the following format:\n",
    "```\n",
    "{\n",
    "    \"0\": {\n",
    "        \"query\": \"$[w={roles}]guitarist <E>musician:[e=PERSON]John plays the piano\",\n",
    "        \"type\": \"syntactic\", # other options are boolean or token \n",
    "        \"case_strategy\": \"ignore\", # other options are exact or smart \n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"roles\"] # should match the name within brackets in the query. Leave empty list if irrelevant.\n",
    "    },\n",
    "    \"1\": {\n",
    "        ...\n",
    "    }...\n",
    "}\n",
    "```\n",
    "2. Lists of words stored in text files under `../data/lists`. The name of the file should match the name in the patterns file. Note you can download the list straight from spike, or create one yourself, with a single item per line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f6f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKE_MATCHES_DIR = '../data/spike_matches'\n",
    "PATTERNS_FILE = 'patterns.json'\n",
    "LISTS_FILE = '../data/lists'\n",
    "# we can either take 1000 and send to file, or take 5000, shuffle and take the first 1000 of the shuffled list\n",
    "LIMIT = 5000\n",
    "MAX_SENTENCES = 1000\n",
    "NEG_PRODUCT = 60 # 10 * len(positive patterns). uncomment if LIMIT is 1000\n",
    "ENTITY_TYPE='PERSON' # the type of entity you are looking for. If your desired capture is not an entity, leave an empty string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623cb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patterns_from_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def write_pattern_matches(pattern):\n",
    "    pattern_matches = search_single_query(pattern)\n",
    "    return pattern_matches\n",
    "\n",
    "        \n",
    "def search_single_query(pattern):\n",
    "    spike_url = \"https://spike.staging.apps.allenai.org\"\n",
    "    stream_location = get_stream_location(spike_url, pattern)\n",
    "    if not stream_location: return None\n",
    "    matches = list(search_stream(spike_url, stream_location, pattern))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def get_lists(pattern):\n",
    "    lists = defaultdict(list)\n",
    "    list_names = pattern[\"lists\"]\n",
    "    if list_names:\n",
    "        for name in list_names:\n",
    "            with open(f\"../data/lists/{name}.txt\", \"r\") as f:\n",
    "                for item in f.readlines():\n",
    "                    lists[name].append(item.strip())\n",
    "    return lists \n",
    "    \n",
    "\n",
    "def get_stream_location(spike_url, pattern):\n",
    "    dataset = \"wikipedia\"\n",
    "    url = spike_url + \"/api/3/multi-search/query\"\n",
    "    query_type = pattern[\"type\"]\n",
    "    query = pattern[\"query\"]\n",
    "    case_strategy = pattern[\"case_strategy\"]\n",
    "    lists = get_lists(pattern)\n",
    "    data= {\n",
    "        \"queries\": {\n",
    "            \"main\": {\n",
    "                query_type: query\n",
    "            }\n",
    "        },\n",
    "        \"data_set_name\": dataset,\n",
    "        \"context\": {\n",
    "            \"lists\": lists,\n",
    "            \"tables\": {\n",
    "            },\n",
    "            \"case_strategy\": case_strategy,\n",
    "            \"attempt_fuzzy\": False\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    if 'stream-location' not in response.headers:\n",
    "        return None\n",
    "    return response.headers['stream-location']\n",
    "\n",
    "\n",
    "def search_stream(spike_url, stream_location, pattern):\n",
    "    stream_url = spike_url + stream_location + f\"?include_sentence=true&limit={LIMIT}&include_sentence=true\"\n",
    "    response = requests.get(stream_url)\n",
    "    results = [json.loads(jl) for jl in response.text.splitlines()]\n",
    "    if len(results) == 0:\n",
    "        print(f\"Couldn't find any results for pattern {pattern}\")\n",
    "    for result in results:\n",
    "        if result['kind'] in ['continuation_url', 'tip']: continue\n",
    "        data = result['value']['sub_matches']['main']\n",
    "        entities = [ent for ent in data['sentence']['entities'] if ent[\"label\"].startswith(ENTITY_TYPE)] if ENTITY_TYPE else []\n",
    "        yield {\n",
    "            'words': data['words'],\n",
    "            'captures': data['captures'],\n",
    "            'sentence_index': data['sentence_index'],\n",
    "            'highlights': data['highlights'],\n",
    "            'entities': entities\n",
    "            }\n",
    "\n",
    "        \n",
    "def main():\n",
    "    patterns = read_patterns_from_file(f'{PATTERNS_FILE}')\n",
    "    for idx, pattern in tqdm(patterns.items()):\n",
    "        max_sents = MAX_SENTENCES*NEG_PRODUCT if pattern[\"label\"] == \"negative\" else MAX_SENTENCES\n",
    "        label = pattern[\"label\"]\n",
    "        with jsonlines.open(f'{SPIKE_MATCHES_DIR}/{label}/{idx}.json', 'w') as f:\n",
    "            matches = write_pattern_matches(pattern)\n",
    "            shuffle(matches)\n",
    "            if matches:\n",
    "                for match in matches[:max_sents]:\n",
    "                    f.write(match)\n",
    "            else:\n",
    "                print(\"no matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cd1a0",
   "metadata": {},
   "source": [
    "### Add Musicians using Hearst Patterns\n",
    "\n",
    "We can use SPIKE to collect names of musicians. Then, call spike API again, for sentences that contain those names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e19454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's currently a bug in using lemma+lists. Replace the ORs with a list once it's fixed. https://github.com/allenai/spike/issues/2056\n",
    "\n",
    "\n",
    "hearst_patterns = {\n",
    "    \"1\": {\n",
    "        \"query\": \"$[l={roles}]musicians $such as <E>musician:e=PERSON\",\n",
    "        \"type\": \"syntactic\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"roles\"]\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"query\": \"<E>musician:[e=PERSON]John $and $other $[l={roles}]musicians\",\n",
    "        \"type\": \"syntactic\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"roles\"]\n",
    "    }, \n",
    "    \"3\": {\n",
    "        \"query\": \"$such $[l={roles}]musicians as <E>musician:[e=PERSON]John\",\n",
    "        \"type\": \"syntactic\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"roles\"]\n",
    "    },\n",
    "    \"4\": {\n",
    "        \"query\": \"<E>musician:[e=PERSON]John is a $[w={roles}]musician\",\n",
    "        \"type\": \"syntactic\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"roles\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826ebbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hearst_based_list_of_musicians(patterns_dict):\n",
    "    musicians = set()\n",
    "\n",
    "    for idx, pattern in patterns_dict.items():\n",
    "        matches = write_pattern_matches(pattern)\n",
    "        for sent in matches:\n",
    "            captures = sent[\"captures\"]\n",
    "            first, last = captures[\"musician\"][\"first\"], captures[\"musician\"][\"last\"]\n",
    "            if first != last:\n",
    "                musician = \" \".join(sent[\"words\"][first:last+1])\n",
    "                musicians.add(musician)\n",
    "    return musicians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7eb75",
   "metadata": {},
   "source": [
    "Create a list of musicians and store it with the rest of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ade4f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LIMIT = 1000\n",
    "musicians = get_hearst_based_list_of_musicians(hearst_patterns)\n",
    "\n",
    "with open(f'{LISTS_FILE}/hearst_musicians.txt', \"w\") as f:\n",
    "    for musician in musicians:\n",
    "        if musician:\n",
    "            f.write(musician+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c6f5c",
   "metadata": {},
   "source": [
    "It is recommended to briefly go over the list to verify there are no weird items. \n",
    "Take this sentence for example, taken from the wikipedia article about [Bonzo Dog Doo-Dah Band](https://en.wikipedia.org/wiki?curid=18949367)\n",
    "```\n",
    "In this number every member of the band was introduced and played a solo, starting with the genuine band members before including such improbable guest musicians as John Wayne on xylophone, Adolf Hitler on vibes, J. Arthur Rank on gong, Prime Minister Harold Wilson on violin, the Wild Man of Borneo, Val Doonican, Horace Batchelor, and Lord Snooty and His Pals.\n",
    "```\n",
    "Retrieval of this sentence inserts \"improbable guest musicians\" such as `Adlof Hitler` and `John Wayne` to the list, though they definitely does not belong there. \n",
    "\n",
    "Add the following pattern to your patterns file. If you run `main()` again, you will get another file with sentences that contain these musicians.\n",
    "\n",
    "```\n",
    "\"7\": {\n",
    "        \"query\": \"musician:w={hearst_musicians}\",\n",
    "        \"type\": \"boolean\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"positive\",\n",
    "        \"lists\": [\"hearst_musicians\"]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ce0e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 8/8 [01:05<00:00,  8.17s/it]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e088e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaningless_query  = {\n",
    "    \"10\": {\n",
    "        \"query\": \"the\",\n",
    "        \"type\": \"boolean\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"negative\",\n",
    "        \"lists\": []\n",
    "    },\n",
    "      \"11\": {\n",
    "        \"query\": \"t=NN\",\n",
    "        \"type\": \"boolean\",\n",
    "        \"case_strategy\": \"ignore\",\n",
    "        \"label\": \"negative\",\n",
    "        \"lists\": []\n",
    "    }\n",
    "                     }\n",
    "\n",
    "for idx, pattern in meaningless_query.items():\n",
    "    sentences = []\n",
    "    matches = write_pattern_matches(pattern)\n",
    "    for sent in matches:\n",
    "        if not sent[\"entities\"]:\n",
    "            sentences.append(sent)\n",
    "\n",
    "    if sentences:\n",
    "        with jsonlines.open(f'{SPIKE_MATCHES_DIR}/negative/{idx}.jsonl', 'w') as f:\n",
    "            shuffle(sentences)\n",
    "            for sent in sentences:\n",
    "                f.write(sent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
